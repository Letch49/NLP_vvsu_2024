{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e866067-6fd5-465a-92df-1e3159dea801",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymorphy3 # for python < 3.11 install pymorphy2\n",
    "!pip install pymystem3\n",
    "!pip install nltk\n",
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614570d3-e523-4b23-9288-b49f4ff50906",
   "metadata": {},
   "source": [
    "## При обработке текстов выделяют несколько этапов анализа.\n",
    "\n",
    "1. Токенизация (графематический анализ) - выделение абзацев, предложений, токенов. Если абзацы в HTML выделяются довольно просто - по тегам <p>, то с выделением предложений и слов могут быть проблемы. ```Г. Мурманск был основан 3 апреля 1915 г. ниже впадения р. Туломы в Кольский залив. Минимальные IP-адреса: 109.124.97.0 - 109.124.97.3.```\n",
    "2. Морфологический анализ (стемминг, лемматизация) - определение начальной формы слова или его псевдопрефикса, грамматических параметров. Подробнее описан ниже.\n",
    "3. Синтаксический анализ - определение связей между словами (деревья зависимостей) или синтаксически связанных групп слов (деревья составляющих). Первые больше подходят для русского языка, вторые - для английского."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9a0bb-53f2-40bb-a48b-e9124fafaa9b",
   "metadata": {},
   "source": [
    "[Деревья зависимостей](https://en.wikipedia.org/wiki/Dependency_grammar)\n",
    "![Деревья зависимостей](https://camo.githubusercontent.com/69c14a92ea941425c457f68d31c8c82d689cc0bdd03084834e1206304304b24a/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30642f5765617265747279696e67746f756e6465727374616e64746865646966666572656e63655f253238322532392e6a7067)\n",
    "\n",
    "\n",
    "[Деревья составляющих](https://en.wikipedia.org/wiki/Constituent_(linguistics))\n",
    "![Деревья составляющих](https://camo.githubusercontent.com/bcc935da739466a3db252c38cb5eb57145c0da984212c5f7277848663848aac7/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f342f34392f436f6d706574696e675f73656e74656e63655f6469616772616d732e706e672f37353070782d436f6d706574696e675f73656e74656e63655f6469616772616d732e706e67)\n",
    "\n",
    "- Семантический анализ - определение смысла слова и работа с ним (```за'мок``` vs ```замо'к```, удаление ребра связанного графа; не путать с ```он видел их семью своими глазами``` где имеет место грамматическая неоднозначность ```семья-семь```).\n",
    "\n",
    "Задачей морфологического анализа является определение начальной формы слова, его части речи и грамматических параметров. В некоторых случаях от слова требуется только начальная форма, в других - только начальная форма и часть речи.\n",
    "\n",
    "Существует два больших подхода к морфологическому анализу: **стемминг** и **поиск по словарю**. Для проведения стемминга оставляется справочник всех окончаний для данного языка. Для пришедшего слова проверяется его окончание и по нему делается прогноз начальной формы и части речи.\n",
    "Например, мы создаем справочник, в котором записываем все окончания прилагательных: -ому, -ему, -ой, -ая, -ий, -ый, ... Теперь все слова, которые имеют такое окончание будут считаться прилагаельными: синий, циклический, красного, больному. Заодно прилагательными будут считаться причастия (делающий, строившему) и местоимения (мой, твой, твоему). Также не понятно что делать со словами, имеющими пустое окончание. Отдельную проблему составляют такие слова, как стекло, больной, вина, которые могут разбираться несколькими вариантами (это явление называется омонимией). Помимо этого, стеммер может просто откусывать окончания, оставляя лишь псевдооснову.\n",
    "\n",
    "Большинство проблем здесь решается, но точность работы бессловарных стеммеров находится на уровне 80%. Чтобы повысить точность испольуют морфологический анализ со словарем. Разработчики составляют словарь слов, встретившихся в текстах (здесь можно найти пример такого словаря). Теперь каждое слово будет искаться в словаре и не предсказываться, а выдаваться точно. Для слов, отсутствующих в словаре, может применяться предсказание, пообное работе стеммера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e328df-e895-41da-b2f7-c3def94a9850",
   "metadata": {},
   "source": [
    "### Морфологический анализ\n",
    "Есть несколько наиболее распространенных библиотеки для морфологического анализа текстов на Python: pymorphy2, pymystem и nltk. Рассмотрим работу с ними.\n",
    "\n",
    "Библиотеки pymorphy основана на словаре [OpenCorpora](https://opencorpora.org/) и позволяет проводить анализ отдельных слов, то есть предварительно необходимо провести графематический анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3055bd60-c414-4eae-980a-760632a5638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,nomn'), normal_form='стекло', score=0.690476, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 0),)),\n",
      " Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,accs'), normal_form='стекло', score=0.285714, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 3),)),\n",
      " Parse(word='стекло', tag=OpencorporaTag('VERB,perf,intr neut,sing,past,indc'), normal_form='стечь', score=0.023809, methods_stack=((DictionaryAnalyzer(), 'стекло', 1015, 3),))]\n"
     ]
    }
   ],
   "source": [
    "import pymorphy3\n",
    "from pprint import pprint\n",
    "morph=pymorphy3.MorphAnalyzer() # Создает объект морфоанализатора и загружет словарь.\n",
    "wordform=morph.parse('стекло')  # Проведем анализ слова \"стекло\"...\n",
    "pprint(wordform)                 # ... и посмотрим на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9e78e-9021-4e70-9386-c2b97108c889",
   "metadata": {},
   "source": [
    "OpeccorporaTag - это объект, представляющий морфологическую информацию о слове в рамках русского языка в системе OpenCorpora. Этот объект содержит информацию о частях речи, роде, числе, падеже и других грамматических характеристиках слова.\n",
    "\n",
    "Теперь, если мы анализируем слово \"стекло\" с новым списком морфологических разборов:\n",
    "\n",
    "1. Существительное \"стекло\" в именительном падеже единственного числа, среднего рода. Вероятность этой формы составляет 69.05%.\n",
    "2. Существительное \"стекло\" в винительном падеже единственного числа, среднего рода. Вероятность этой формы составляет 28.57%.\n",
    "3. Глагол \"стечь\" в прошедшем времени единственного числа, среднего рода. Вероятность этой формы составляет 2.38%.\n",
    "\n",
    "Снова применяя самый простой метод выбора начальной формы, мы можем сказать, что слово \"стекло\" скорее всего используется в форме существительного в именительном падеже, так как это наиболее вероятная форма с вероятностью около 69%. Этот подход обеспечивает примерно 90% точности при выборе начальной формы и до 80% точности при учете грамматических параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96a0a06-2ab2-4f41-9895-52fc6a4d9bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690476"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94f2bbe-4525-48b6-aab5-f63499aec228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpencorporaTag('NOUN,inan,neut sing,nomn')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d411e1e-96b0-4804-8ff8-71286bc5dcfb",
   "metadata": {},
   "source": [
    "Описание OpencorporaTag('NOUN,inan,neut sing,nomn'):\n",
    "\n",
    "1. NOUN: Это указывает на часть речи слова, в данном случае, существительное.\n",
    "2. inan: Это указывает на неодушевленность существительного, что означает, что это не живое существо или неодушевленный объект.\n",
    "3. neut: Это указывает на род существительного, в данном случае, средний род.\n",
    "4. sing: Это указывает на число, в данном случае, единственное число (существительное имеет только одну форму).\n",
    "5. nomn: Это указывает на падеж существительного, в данном случае, именительный падеж (когда существительное выполняет функцию подлежащего в предложении).\n",
    "\n",
    "[Полный список](https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e06906-66a0-467d-a0e2-13b893352abe",
   "metadata": {},
   "source": [
    "Pymorphy умеет синтезировать нужные нам формы слова. Для этого необходимо получить объект типа Parse для нужного слова, а затем вызвать функцию inflect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529eba2d-1a55-415c-acd6-2950fa387dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='стёклам', tag=OpencorporaTag('NOUN,inan,neut plur,datv'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёклам', 157, 8),))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform[0].inflect({'plur','datv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0c4876-9ac9-4d37-abaf-1ce7880a9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,nomn'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 0),))\n",
      "Parse(word='стекла', tag=OpencorporaTag('NOUN,inan,neut sing,gent'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стекла', 157, 1),))\n",
      "Parse(word='стеклу', tag=OpencorporaTag('NOUN,inan,neut sing,datv'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стеклу', 157, 2),))\n",
      "Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,accs'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 3),))\n",
      "Parse(word='стеклом', tag=OpencorporaTag('NOUN,inan,neut sing,ablt'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стеклом', 157, 4),))\n",
      "Parse(word='стекле', tag=OpencorporaTag('NOUN,inan,neut sing,loct'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стекле', 157, 5),))\n",
      "Parse(word='стёкла', tag=OpencorporaTag('NOUN,inan,neut plur,nomn'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёкла', 157, 6),))\n",
      "Parse(word='стёкол', tag=OpencorporaTag('NOUN,inan,neut plur,gent'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёкол', 157, 7),))\n",
      "Parse(word='стёклам', tag=OpencorporaTag('NOUN,inan,neut plur,datv'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёклам', 157, 8),))\n",
      "Parse(word='стёкла', tag=OpencorporaTag('NOUN,inan,neut plur,accs'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёкла', 157, 9),))\n",
      "Parse(word='стёклами', tag=OpencorporaTag('NOUN,inan,neut plur,ablt'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёклами', 157, 10),))\n",
      "Parse(word='стёклах', tag=OpencorporaTag('NOUN,inan,neut plur,loct'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стёклах', 157, 11),))\n"
     ]
    }
   ],
   "source": [
    "for item in wordform[0].lexeme:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aefcf4-aa95-48a8-848d-bf5504f6d612",
   "metadata": {},
   "source": [
    "А ещё pymorphy умеет предсказывать незнакомые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea28e3d-cc89-4d62-9251-d9e546e7c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='флексить', tag=OpencorporaTag('INFN,perf,tran'), normal_form='флексить', score=1.0, methods_stack=((FakeDictionary(), 'флексить', 858, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'ксить')))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform=morph.parse('флексить') \n",
    "wordform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d98483-2bb8-4e3e-877b-7ac46192f5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "флексить 1.0 INFN,perf,tran\n",
      "флексил 1.0 VERB,perf,tran masc,sing,past,indc\n",
      "флексила 1.0 VERB,perf,tran femn,sing,past,indc\n",
      "флексило 1.0 VERB,perf,tran neut,sing,past,indc\n",
      "флексили 1.0 VERB,perf,tran plur,past,indc\n",
      "флекшу 1.0 VERB,perf,tran sing,1per,futr,indc\n",
      "флексим 1.0 VERB,perf,tran plur,1per,futr,indc\n",
      "флексишь 1.0 VERB,perf,tran sing,2per,futr,indc\n",
      "флексите 1.0 VERB,perf,tran plur,2per,futr,indc\n",
      "флексит 1.0 VERB,perf,tran sing,3per,futr,indc\n",
      "флексят 1.0 VERB,perf,tran plur,3per,futr,indc\n",
      "флексим 1.0 VERB,perf,tran sing,impr,incl\n",
      "флексимте 1.0 VERB,perf,tran plur,impr,incl\n",
      "флекси 1.0 VERB,perf,tran sing,impr,excl\n",
      "флексите 1.0 VERB,perf,tran plur,impr,excl\n",
      "флексивший 1.0 PRTF,perf,tran,past,actv masc,sing,nomn\n",
      "флексившего 1.0 PRTF,perf,tran,past,actv masc,sing,gent\n",
      "флексившему 1.0 PRTF,perf,tran,past,actv masc,sing,datv\n",
      "флексившего 1.0 PRTF,perf,tran,past,actv anim,masc,sing,accs\n",
      "флексивший 1.0 PRTF,perf,tran,past,actv inan,masc,sing,accs\n",
      "флексившим 1.0 PRTF,perf,tran,past,actv masc,sing,ablt\n",
      "флексившем 1.0 PRTF,perf,tran,past,actv masc,sing,loct\n",
      "флексившая 1.0 PRTF,perf,tran,past,actv femn,sing,nomn\n",
      "флексившей 1.0 PRTF,perf,tran,past,actv femn,sing,gent\n",
      "флексившей 1.0 PRTF,perf,tran,past,actv femn,sing,datv\n",
      "флексившую 1.0 PRTF,perf,tran,past,actv femn,sing,accs\n",
      "флексившей 1.0 PRTF,perf,tran,past,actv femn,sing,ablt\n",
      "флексившею 1.0 PRTF,perf,tran,past,actv femn,sing,ablt,V-ey\n",
      "флексившей 1.0 PRTF,perf,tran,past,actv femn,sing,loct\n",
      "флексившее 1.0 PRTF,perf,tran,past,actv neut,sing,nomn\n",
      "флексившего 1.0 PRTF,perf,tran,past,actv neut,sing,gent\n",
      "флексившему 1.0 PRTF,perf,tran,past,actv neut,sing,datv\n",
      "флексившее 1.0 PRTF,perf,tran,past,actv neut,sing,accs\n",
      "флексившим 1.0 PRTF,perf,tran,past,actv neut,sing,ablt\n",
      "флексившем 1.0 PRTF,perf,tran,past,actv neut,sing,loct\n",
      "флексившие 1.0 PRTF,perf,tran,past,actv plur,nomn\n",
      "флексивших 1.0 PRTF,perf,tran,past,actv plur,gent\n",
      "флексившим 1.0 PRTF,perf,tran,past,actv plur,datv\n",
      "флексивших 1.0 PRTF,perf,tran,past,actv anim,plur,accs\n",
      "флексившие 1.0 PRTF,perf,tran,past,actv inan,plur,accs\n",
      "флексившими 1.0 PRTF,perf,tran,past,actv plur,ablt\n",
      "флексивших 1.0 PRTF,perf,tran,past,actv plur,loct\n",
      "флекшенный 1.0 PRTF,perf,tran,past,pssv masc,sing,nomn\n",
      "флекшенного 1.0 PRTF,perf,tran,past,pssv masc,sing,gent\n",
      "флекшенному 1.0 PRTF,perf,tran,past,pssv masc,sing,datv\n",
      "флекшенного 1.0 PRTF,perf,tran,past,pssv anim,masc,sing,accs\n",
      "флекшенный 1.0 PRTF,perf,tran,past,pssv inan,masc,sing,accs\n",
      "флекшенным 1.0 PRTF,perf,tran,past,pssv masc,sing,ablt\n",
      "флекшенном 1.0 PRTF,perf,tran,past,pssv masc,sing,loct\n",
      "флекшенная 1.0 PRTF,perf,tran,past,pssv femn,sing,nomn\n",
      "флекшенной 1.0 PRTF,perf,tran,past,pssv femn,sing,gent\n",
      "флекшенной 1.0 PRTF,perf,tran,past,pssv femn,sing,datv\n",
      "флекшенную 1.0 PRTF,perf,tran,past,pssv femn,sing,accs\n",
      "флекшенной 1.0 PRTF,perf,tran,past,pssv femn,sing,ablt\n",
      "флекшенною 1.0 PRTF,perf,tran,past,pssv femn,sing,ablt,V-oy\n",
      "флекшенной 1.0 PRTF,perf,tran,past,pssv femn,sing,loct\n",
      "флекшенное 1.0 PRTF,perf,tran,past,pssv neut,sing,nomn\n",
      "флекшенного 1.0 PRTF,perf,tran,past,pssv neut,sing,gent\n",
      "флекшенному 1.0 PRTF,perf,tran,past,pssv neut,sing,datv\n",
      "флекшенное 1.0 PRTF,perf,tran,past,pssv neut,sing,accs\n",
      "флекшенным 1.0 PRTF,perf,tran,past,pssv neut,sing,ablt\n",
      "флекшенном 1.0 PRTF,perf,tran,past,pssv neut,sing,loct\n",
      "флекшенные 1.0 PRTF,perf,tran,past,pssv plur,nomn\n",
      "флекшенных 1.0 PRTF,perf,tran,past,pssv plur,gent\n",
      "флекшенным 1.0 PRTF,perf,tran,past,pssv plur,datv\n",
      "флекшенных 1.0 PRTF,perf,tran,past,pssv anim,plur,accs\n",
      "флекшенные 1.0 PRTF,perf,tran,past,pssv inan,plur,accs\n",
      "флекшенными 1.0 PRTF,perf,tran,past,pssv plur,ablt\n",
      "флекшенных 1.0 PRTF,perf,tran,past,pssv plur,loct\n",
      "флексив 1.0 GRND,perf,tran past\n",
      "флексивши 1.0 GRND,perf,tran past,V-sh\n",
      "флекшен 1.0 PRTS,perf,past,pssv masc,sing\n",
      "флекшена 1.0 PRTS,perf,past,pssv femn,sing\n",
      "флекшено 1.0 PRTS,perf,past,pssv neut,sing\n",
      "флекшены 1.0 PRTS,perf,past,pssv plur\n"
     ]
    }
   ],
   "source": [
    "for item in wordform[0].lexeme:\n",
    "    print(item.word, item.score, item.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d812c-ffb1-48c7-b67c-1f10aa09e451",
   "metadata": {},
   "source": [
    "Вместо Pymorphy можно использовать PyMystem. Его плюсом является тот факт, что он сам проводит графематический анализ и снимает омонимию.\n",
    "\n",
    "Функция lemmatize делит текст на слова и знаки препинания, а затем возвращает для них только начальную форму.\n",
    "\n",
    "Функция analyze возвращает не только начальную форму, но и всю информацию о слове, как это делал перед этим Pymorphy.\n",
    "\n",
    "Как видно из примера, делает он это не всегда корректно, но нам не придется думать о том, какое вариант разбора следует взять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead50b95-4d40-4618-ae8c-500a3e2e605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a241bd9b-3bc1-4569-8872-18133f18de7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['этот',\n",
      " ' ',\n",
      " 'тип',\n",
      " ' ',\n",
      " 'становиться',\n",
      " ' ',\n",
      " 'есть',\n",
      " ' ',\n",
      " 'в',\n",
      " ' ',\n",
      " 'цех',\n",
      " '.',\n",
      " '\\n']\n",
      "[{'analysis': [{'gr': 'APRO=(им,мн|вин,мн,неод)', 'lex': 'этот', 'wt': 1}],\n",
      "  'text': 'эти'},\n",
      " {'text': ' '},\n",
      " {'analysis': [{'gr': 'S,муж,неод=(вин,мн|им,мн)',\n",
      "                'lex': 'тип',\n",
      "                'wt': 0.8700298642}],\n",
      "  'text': 'типы'},\n",
      " {'text': ' '},\n",
      " {'analysis': [{'gr': 'V,нп=прош,мн,изъяв,сов',\n",
      "                'lex': 'становиться',\n",
      "                'wt': 0.9821285244}],\n",
      "  'text': 'стали'},\n",
      " {'text': ' '},\n",
      " {'analysis': [{'gr': 'V,несов,пе=инф', 'lex': 'есть', 'wt': 0.0492236161}],\n",
      "  'text': 'есть'},\n",
      " {'text': ' '},\n",
      " {'analysis': [{'gr': 'PR=', 'lex': 'в', 'wt': 0.9999917878}], 'text': 'в'},\n",
      " {'text': ' '},\n",
      " {'analysis': [{'gr': 'S,муж,неод=(дат,ед|местн,ед)', 'lex': 'цех', 'wt': 1}],\n",
      "  'text': 'цеху'},\n",
      " {'text': '.'},\n",
      " {'text': '\\n'}]\n"
     ]
    }
   ],
   "source": [
    "mystem=pymystem3.Mystem()\n",
    "pprint(mystem.lemmatize('эти типы стали есть в цеху.'))\n",
    "pprint(mystem.analyze('эти типы стали есть в цеху.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46750c-3e5f-47ef-a695-6264241ce0fb",
   "metadata": {},
   "source": [
    "То есть результатом является список токенов (в том числе и пробельных или знаков препинания), для части из которых имеется результат анализа, который хранится в словаре с ключём analysis. Анализ хранит в списке один или несколько вариантов разбора, у каждого из которых есть лемма lex, набор грамматических параметров gr и некоторый вес wt, который показывает степень уверенности системы в правильности ответа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b486a80f-b404-4a0f-ad28-32a5088118a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APRO\n"
     ]
    }
   ],
   "source": [
    "my_res=mystem.analyze('эти типы стали есть в цеху.')\n",
    "if 'analysis' in my_res[0].keys(): # Проверяем, что это не разделитель.\n",
    "    print(my_res[0]['analysis'][0]['gr'].split(\"=\")[0]) # Берем из него анализ, из того грамматическсие параметы, \n",
    "                                                        # а из них выделяем часть речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e981f6-fbd8-4a98-a22d-781d38707e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # Иностранный морфологический анализатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58824d3-eff2-4e5e-aa2c-8e31dbaf2a89",
   "metadata": {},
   "source": [
    "Перед началом использования необходимо загрузить необходимые библиотеки или корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c369d2b-6a24-4281-85c3-3b3d8cc55a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() # По дороге будут появляться поле ввода. Грузит всё из Сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c7d0f2-adbb-4b69-b65c-45a1d7a3ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     /Users/roman/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/roman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/roman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(['averaged_perceptron_tagger_ru', 'stopwords', 'punkt']) # можно скачать сразу нужные пакеты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815aa07b-a243-4214-8d14-8fbb5f232d34",
   "metadata": {},
   "source": [
    "Функция word_tokenize возвращает начальные формы слов.\n",
    "\n",
    "Функция pos_tag возвращает список начальных форм и их частей речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e47f524-459a-43eb-b38e-08c26cde7c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Эти', 'типы', 'стали', 'есть', 'в', 'цеху']\n",
      "[('Эти', 'типы'),\n",
      " ('типы', 'стали'),\n",
      " ('стали', 'есть'),\n",
      " ('есть', 'в'),\n",
      " ('в', 'цеху')]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize('Эти типы стали есть в цеху') # Токенизация.\n",
    "bi_tokens = list(nltk.bigrams(tokens))\n",
    "pprint(tokens)\n",
    "pprint(bi_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029fc911-2fbb-4240-8f1b-7f16b97a7e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Эти', 'JJ'),\n",
       "  ('типы', 'NNP'),\n",
       "  ('стали', 'NNP'),\n",
       "  ('есть', 'NNP'),\n",
       "  ('в', 'NNP'),\n",
       "  ('цеху', 'NN')],\n",
       " [(('Эти', 'JJ'), ('типы', 'NNP')),\n",
       "  (('типы', 'NNP'), ('стали', 'NNP')),\n",
       "  (('стали', 'NNP'), ('есть', 'NNP')),\n",
       "  (('есть', 'NNP'), ('в', 'NNP')),\n",
       "  (('в', 'NNP'), ('цеху', 'NN'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = nltk.pos_tag(tokens) # Частеречная разметка.\n",
    "bi_pos = list(nltk.bigrams(pos))\n",
    "pos, bi_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220c2b4-6dd2-40b0-9e80-8da625808f21",
   "metadata": {},
   "source": [
    "У NLTK заведен список стоп-слов, которые лучше фильтровать при анализе текстов. Но их не очень много. Зато самые мешающиеся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5fb571-4e96-4ee0-af1c-738d5dbb86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего русских стоп-слов 151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Эти', 'типы', 'стали', 'цеху']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оставим только те слова, которых нет в списке стоп-слов.\n",
    "filtered_words = [token for token in tokens if token not in nltk.corpus.stopwords.words('russian')]\n",
    "print('всего русских стоп-слов', len(nltk.corpus.stopwords.words('russian')))\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4beeeac5-c504-452c-8086-64a98263eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5233fe5-600d-4038-9cbb-7e7b033918fd",
   "metadata": {},
   "source": [
    "Ту же самую задачу в других библиотеках можно решить при помощи фильтра частей речи. Можно считать, что значимыми являются лишь существительные, прилагательные, глаголы, причастия и деепричастия. Ниже приведены названия частей речи для разных библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863f45e-d993-4a5a-8a7b-a6fb7558d93b",
   "metadata": {},
   "source": [
    "Существует простая в использовании библиотека Natasha, которая позволяет сделать все тоже самое очень простыми действиями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f69933e8-1001-47b1-970d-09adc6f737fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a0b43e9-b61b-4d22-8e71-4ab0daa9cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter() # токенизация\n",
    "morph_vocab = MorphVocab() # морфология\n",
    "\n",
    "emb = NewsEmbedding() # построение эмбедингов\n",
    "morph_tagger = NewsMorphTagger(emb) # разметка морфологии\n",
    "syntax_parser = NewsSyntaxParser(emb) # разметка синтаксиса\n",
    "ner_tagger = NewsNERTagger(emb) # разметка именованых сущностей\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "\n",
    "text = 'Г. Мурманск был основан 3 апреля 1915 г. ниже впадения р. Туломы в Кольский залив. Минимальные IP-адреса: 109.124.97.0 - 109.124.97.3.'\n",
    "doc = Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b60c0579-0eb2-4018-8537-edf5e19ee967",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.segment(segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27c411b5-e410-4cd7-a172-4ca969537f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocToken(stop=1, text='Г'),\n",
       " DocToken(start=1, stop=2, text='.'),\n",
       " DocToken(start=3, stop=11, text='Мурманск'),\n",
       " DocToken(start=12, stop=15, text='был'),\n",
       " DocToken(start=16, stop=23, text='основан'),\n",
       " DocToken(start=24, stop=25, text='3'),\n",
       " DocToken(start=26, stop=32, text='апреля'),\n",
       " DocToken(start=33, stop=37, text='1915'),\n",
       " DocToken(start=38, stop=39, text='г'),\n",
       " DocToken(start=39, stop=40, text='.'),\n",
       " DocToken(start=41, stop=45, text='ниже'),\n",
       " DocToken(start=46, stop=54, text='впадения'),\n",
       " DocToken(start=55, stop=56, text='р'),\n",
       " DocToken(start=56, stop=57, text='.'),\n",
       " DocToken(start=58, stop=64, text='Туломы'),\n",
       " DocToken(start=65, stop=66, text='в'),\n",
       " DocToken(start=67, stop=75, text='Кольский'),\n",
       " DocToken(start=76, stop=81, text='залив'),\n",
       " DocToken(start=81, stop=82, text='.'),\n",
       " DocToken(start=83, stop=94, text='Минимальные'),\n",
       " DocToken(start=95, stop=104, text='IP-адреса'),\n",
       " DocToken(start=104, stop=105, text=':'),\n",
       " DocToken(start=106, stop=118, text='109.124.97.0'),\n",
       " DocToken(start=119, stop=120, text='-'),\n",
       " DocToken(start=121, stop=133, text='109.124.97.3'),\n",
       " DocToken(start=133, stop=134, text='.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3694416e-32b7-4923-9ce4-13e7ce593f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocSent(stop=82, text='Г. Мурманск был основан 3 апреля 1915 г. ниже впа..., tokens=[...]),\n",
       " DocSent(start=83, stop=134, text='Минимальные IP-адреса: 109.124.97.0 - 109.124.97...., tokens=[...])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3f15757-53c9-4481-9173-40b542bdb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.tag_morph(morph_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ae91e3f-5252-47cf-9a0d-c3af85a6a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Г PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   . PUNCT\n",
      "            Мурманск PROPN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "                 был AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "             основан VERB|Aspect=Perf|Gender=Masc|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
      "                   3 ADJ\n",
      "              апреля NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                1915 ADJ\n",
      "                   г NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   . PUNCT\n",
      "                ниже ADJ|Degree=Cmp\n",
      "            впадения NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   р NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "                   . PUNCT\n",
      "              Туломы PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   в ADP\n",
      "            Кольский ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
      "               залив NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
      "                   . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc.sents[0].morph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f86b11a-b6e1-49d1-bb40-b2964fefa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b4f2dce-afc8-480c-be29-b74daa77d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Г': 'г',\n",
       " '.': '.',\n",
       " 'Мурманск': 'мурманск',\n",
       " 'был': 'быть',\n",
       " 'основан': 'основать',\n",
       " '3': '3',\n",
       " 'апреля': 'апрель',\n",
       " '1915': '1915',\n",
       " 'г': 'г',\n",
       " 'ниже': 'ниже',\n",
       " 'впадения': 'впадение',\n",
       " 'р': 'р',\n",
       " 'Туломы': 'тулома',\n",
       " 'в': 'в',\n",
       " 'Кольский': 'кольский',\n",
       " 'залив': 'залив',\n",
       " 'Минимальные': 'минимальный',\n",
       " 'IP-адреса': 'ip-адрес',\n",
       " ':': ':',\n",
       " '109.124.97.0': '109.124.97.0',\n",
       " '-': '-',\n",
       " '109.124.97.3': '109.124.97.3'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5df2ea6c-1cac-4bed-a8b4-c177939da589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌──► Г        nsubj:pass\n",
      "        │    .        \n",
      "        │    Мурманск \n",
      "        │ ┌► был      aux:pass\n",
      "┌─┌─┌───└─└─ основан  \n",
      "│ │ │ ┌─└►┌─ 3        obl\n",
      "│ │ │ │   └► апреля   flat\n",
      "│ │ │ │   ┌► 1915     amod\n",
      "│ │ │ └──►└─ г        nmod\n",
      "│ │ └──────► .        punct\n",
      "│ │       ┌► ниже     case\n",
      "│ │   ┌─┌►└─ впадения nmod\n",
      "│ │   └►└─┌─ р        nmod\n",
      "│ │       │  .        \n",
      "│ │       └► Туломы   appos\n",
      "│ │     ┌──► в        case\n",
      "│ │     │ ┌► Кольский amod\n",
      "│ └────►└─└─ залив    obl\n",
      "└──────────► .        punct\n"
     ]
    }
   ],
   "source": [
    "doc.parse_syntax(syntax_parser)\n",
    "doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ecbb68e-0bcb-453b-85e4-d7ba1e5ac7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Г. Мурманск был основан 3 апреля 1915 г. ниже впадения р. Туломы в \n",
      "   LOC─────                                                        \n",
      "Кольский залив. Минимальные IP-адреса: 109.124.97.0 - 109.124.97.3.\n",
      "LOC───────────                                                     \n"
     ]
    }
   ],
   "source": [
    "doc.tag_ner(ner_tagger)\n",
    "doc.ner.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e918bc-be24-4ffe-967c-15a0b346d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
